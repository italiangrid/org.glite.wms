##############################################################################
# Copyright (c) Members of the EGEE Collaboration. 2004. 
# See http://www.eu-egee.orgpartners/ for details on the copyright 
# holders.  
#
# Licensed under the Apache License, Version 2.0 (the "License"); 
# you may not use this file except in compliance with the License. 
# You may obtain a copy of the License at 
#
#    http://www.apache.org/licenses/LICENSE-2.0 
#
# Unless required by applicable law or agreed to in writing, software 
# distributed under the License is distributed on an "AS IS" BASIS, 
# WITHOUT WARRANTIES OR CONDITIONS 
# OF ANY KIND, either express or implied. 
# See the License for the specific language governing permissions and 
# limitations under the License.
##############################################################################
#
# NAME :        site-info.def
#
# DESCRIPTION : This is the main configuration file needed to execute the
#               yaim command. It contains a list of the variables needed to
#               configure a service.
#
# AUTHORS :     yaim-contact@cern.ch
#
# NOTES :       - site-info.def currently contains the whole list of variables
#                 needed to configure a site. However we have started to  move
#                 towards a new approach where node type specific variables will 
#                 be distributed by its corresponding module. 
#                 Although a unique site-info.def can still be used at configuration time.
#               
#               - Service specific variables will be distributed under 
#                 /opt/glite/yaim/examples/siteinfo/services/glite_<node_type_name>
#                 The definition of the variables can be done there or copy them in site-info.def.  
#
#               - VO variables are currently distributed for a number of VOs with
#                 real values that can be directly used by sys admins.
#                 We have started to move towards a new approach where yaim will no longer distribute
#                 these variables. Instead, VO values will be downloaded directly from the CIC
#                 portal and will be integrated using the YAIM configurator.
#
#               - For more information on YAIM, please check:
#                 https://twiki.cern.ch/twiki/bin/view/EGEE/YAIM
#
#               - For more details on the CIC portal, visit:
#                 http://cic.in2p3.fr/
#                 To know more about the YAIM configurator go to the VO management section.
#
# YAIM MODULE:  glite-yaim-core
#                 
##############################################################################

##########################
# YAIM related variables #
##########################

# This a variable to debug your configuration.
# If it is set, functions will print debugging information.
# Values: NONE, ABORT, ERROR, WARNING, INFO, DEBUG
YAIM_LOGGING_LEVEL=DEBUG

# Repository settings
# Be aware that the install option is only available for 3.0 services.
# You can ignore this variables if you are configuring a 3.1 service.
#LCG_REPOSITORY="'http://grid-deployment.web.cern.ch/grid-deployment/glite/cert/3.1/glite-TORQUE_client/sl4/i386/' 'http://grid-deployment.web.cern.ch/grid-deployment/glite/cert/3.1/glite-UI/sl4/i386/' 'http://grid-deployment.web.cern.ch/grid-deployment/glite/cert/3.1/glite-TORQUE_utils/sl4/i386/'"
#CA_REPOSITORY="http://linuxsoft.cern.ch/LCG-CAs/current"
#REPOSITORY_TYPE="yum"

###################################
# General configuration variables #
###################################

MY_DOMAIN="cern.ch"
INSTALL_ROOT=/opt

# These variables tell YAIM where to find additional configuration files.
WN_LIST=/afs/cern.ch/project/gd/yaim-server/cert-TB-config/site-TB/wn-list.conf
USERS_CONF=/etc/yaim/users.conf
GROUPS_CONF=/etc/yaim/groups.conf
FUNCTIONS_DIR=/opt/glite/yaim/functions

# gLite pool account home directory
# Please, uncomment this variable is you want to specify a home directory different from /home.
# USER_HOME_PREFIX=my_home_directory

# Set this to "yes" if your site provides an X509toKERBEROS Authentication Server
# Only for sites with Experiment Software Area under AFS
GSSKLOG=no
GSSKLOG_SERVER=my-gssklog.$MY_DOMAIN

OUTPUT_STORAGE=/tmp/jobOutput
JAVA_LOCATION="/usr/java/jdk1.5.0_14/"

# Set this to '/dev/null' or some other dir if you want
# to turn off yaim installation of cron jobs
CRON_DIR=/etc/cron.d

# Set this to your prefered and firewall allowed port range
# YAIM automatically handles the syntax of this variable depending on the version of VDT. 
# If it is VDT 1.6 it leaves "num1,num2". If it is a version < VDT 1.6 it changes to "num1 num2". 
GLOBUS_TCP_PORT_RANGE="20000,25000"

# Choose a good password !
# And be sure that this file cannot be read by any grid job !
MYSQL_PASSWORD="InMySQLWeTrust"


CREAMCE_HOST=lxbra2308.$MY_DOMAIN
CE_HOST=lxbra2307.$MY_DOMAIN

# Site-wide settings
SITE_EMAIL=lcg-test-beds.administrators@cern.ch
SITE_CRON_EMAIL=$SITE_EMAIL  # not yet used will appear in a later release
SITE_SUPPORT_EMAIL=$SITE_EMAIL
SITE_NAME=cert-tb-cern
SITE_LOC="Geneva, Switzerland"
SITE_LAT=46.20 # -90 to 90 degrees
SITE_LONG=6.1 # -180 to 180 degrees
SITE_WEB="https://twiki.cern.ch/twiki/bin/view/EGEE/EGEETestbeds"
#SITE_TIER="TIER 0"
#SITE_SUPPORT_SITE="cert-tb-cern"
#SITE_HTTP_PROXY=""
SITE_DESC=CERN_CERT_TB
SITE_SECURITY_EMAIL="lcg-test-beds.administrators@cern.ch"

SITE_OTHER_GRID=EGEE
SITE_OTHER_EGEE_SERVICE=certification

CREAM_DB_USER=creamDB
ACCESS_BY_DOMAIN=force
#BATCH_CONF_DIR=
CEMON_HOST=$CREAMCE_HOST
BLPARSER_HOST=$CREAMCE_HOST
BLP_PORT=33332
#CREAM_PORT

###########################
# monitoring NAGIOS       #
###########################

NAGIOS_HOST="lxbra2302.cern.ch"
NCG_NRPE_UI="lxbra2302.cern.ch"
NAGIOS_ADMIN_DNS="/DC=ch/DC=cern/OU=Organic Units/OU=Users/CN=lponcet/CN=610508/CN=Louis Poncet"
NAGIOS_HTTPD_ENABLE_CONFIG=true

#NCG_MAIN_DB_FILE
#NCG_TEMPLATES_DIR
#NCG_OUTPUT_DIR
#NCG_NRPE_OUTPUT_DIR

#NCG_PROBES_TYPE
# remote,native
#
NAGIOS_HTPASSWD_FILE=/etc/nagios/htpasswd.users
# Location of allowed users for nagios web portal
# NCG_VO

# Set this if your WNs have a shared directory for temporary storage
CE_DATADIR=""

##############################
# CE configuration variables #
##############################




# Architecture and enviroment specific settings
CE_CPU_MODEL=Xeon
CE_CPU_VENDOR=intel
CE_CPU_SPEED=2334
CE_OS="Scientific Linux"
CE_OS_RELEASE=4.6
CE_OS_VERSION="SLC"
# CE_OS_ARCH should be set to result of `uname -m` runned on WN
CE_OS_ARCH=i686
CE_MINPHYSMEM=16632960
CE_MINVIRTMEM=512
CE_PHYSCPU=4
CE_LOGCPU=1
CE_SMPSIZE=2
CE_SI00=381
CE_SF00=0
CE_OUTBOUNDIP=TRUE
CE_INBOUNDIP=FALSE
CE_RUNTIMEENV="
    LCG-2
    LCG-2_1_0
    LCG-2_1_1
    LCG-2_2_0
    LCG-2_3_0
    LCG-2_3_1
    LCG-2_4_0
    LCG-2_5_0
    LCG-2_6_0
    LCG-2_7_0
    GLITE-3_0_0
    GLITE-3_1_0
    R-GMA
"

##############################
# RB configuration variables #
##############################

RB_HOST=lxbra2303.$MY_DOMAIN

###############################
# WMS configuration variables #
###############################

WMS_HOST=lxbra2303.$MY_DOMAIN

##############################
# LB configuration variables #
##############################

LB_HOST=lxbra2303.$MY_DOMAIN

###################################
# myproxy configuration variables #
###################################

PX_HOST=lxbra2304.$MY_DOMAIN

# GRID_TRUSTED_BROKERS: DNs of services (RBs) allowed to renew/retrives
# credentials from/at the myproxy server. Put single quotes around each trusted DN !!!

GRID_TRUSTED_BROKERS="
'/C=CH/O=CERN/OU=GRID/CN=host/$WMS_HOST'
'/C=CH/O=CERN/OU=GRID/CN=host/lxbra2302.cern.ch'
'/C=CH/O=CERN/OU=GRID/CN=host/lxbra2304.cern.ch'
'*'
"

################################
# RGMA configuration variables #
################################

MON_HOST=lxb7607v1.$MY_DOMAIN
REG_HOST=lxb7607v1.$MY_DOMAIN

###################################
# FTS configuration variables #
###################################

FTS_HOST=lxbra2310.$MY_DOMAIN
FTS_SERVER_URL="https://fts.${MY_DOMAIN}:8443/path/glite-data-transfer-fts"

###############################
# LFC configuration variables #
###############################

LFC_HOST=lxb7608v3.$MY_DOMAIN

LFC_DB_PASSWORD="lfc_password"

# Default value is to put the standard database on the LFC host
LFC_DB_HOST=$LFC_HOST
LFC_DB=cns_db

# If you use a DNS alias in front of your LFC, specify it here
# LFC_HOST_ALIAS="cert-fts-64.$MY_DOMAIN"

# All catalogues are local unless you add a VO to
# LFC_CENTRAL, in which case that will be central
LFC_CENTRAL="atlas alice lhcb cms dteam biomed ops  org.glite.voms-test"
# If you want to limit the VOs your LFC serves, add the locals here
#LFC_LOCAL=""

#########################################
# Torque server configuration variables #
#########################################

# Change this if your torque server is not on the CE
# This is ignored for other batch systems
BATCH_SERVER=$CE_HOST

# Jobmanager specific settings
JOB_MANAGER=lcgpbs
CE_BATCH_SYS=torque
BATCH_BIN_DIR=/usr/bin
BATCH_VERSION=torque-2.3.0
BATCH_LOG_DIR=/var/spool/pbs

#################################
# VOBOX configuration variables #
#################################

VOBOX_HOST=.$MY_DOMAIN
VOBOX_PORT=1975

################################
# APEL configuration variables #
################################

APEL_DB_PASSWORD="APELDB_PWD"

##########################################
# Gridice server configuration variables #
##########################################

# GridIce server host name (usually run on the MON node).
GRIDICE_SERVER_HOST=$MON_HOST

####################################
# E2EMONIT configuration variables #
####################################

# This specifies the location to download the host specific configuration file
E2EMONIT_LOCATION=grid-deployment.web.cern.ch/grid-deployment/e2emonit/production

# Replace this with the siteid supplied by the person setting up the networking
# topology.
E2EMONIT_SITEID=cert-tb-cern

######################################
# SE classic configuration variables #
######################################

# Classic SE
CLASSIC_HOST="lxbra1910.$MY_DOMAIN"
CLASSIC_STORAGE_DIR="/storage"

##################################
# dcache configuration variables #
##################################

# dCache-specific settings
# ignore if you are not running d-cache

# Your dcache admin node
DCACHE_ADMIN="my-admin-node"

# Pools must include host:/absolutePath and may optionally include
# size host:size:/absolutePath if the size is not set the pool will 
# fill the partition it is installed upon. size cannot be smaller 
# than 4 (Gb) unless you are an expert.

DCACHE_POOLS="my-pool-node1:[size]:/pool-path1 my-pool-node2:/pool-path2"

# Optional

# For large sites the load on the admin-node is a limiting factor. Pnfs
# accounts for a lot of this load and so can be placed on a different
# node to balance the load better.


# Set DCACHE_DOOR_* to "off" if you dont want the door to start on any host
#

# DCACHE_DOOR_SRM="door_node1[:port]"
# DCACHE_DOOR_GSIFTP="door_node1[:port] door_node2[:port]"
# DCACHE_DOOR_GSIDCAP="door_node1[:port] door_node2[:port]"
# DCACHE_DOOR_DCAP="door_node1[:port] door_node2[:port]"
# DCACHE_DOOR_XROOTD="door_node1[:port] door_node2[:port]"
# DCACHE_DOOR_LDAP="admin_node"
# DCACHE_DOOR_XROOTD="door_node1[:port] door_node2[:port]"

# This option sets the pnfs server it defaults to the admin node if 
# not stated.
#
# DCACHE_PNFS_SERVER="pnfs_node"
#
# Sets the portrange for dcache as a GSIFTP server in "passive" mode
#
# DCACHE_PORT_RANGE_PROTOCOLS_SERVER_GSIFTP=50000,52000
#
# Sets the portrange for dcache as a (GSI)DCAP and xrootd server in 
# "passive" mode
#
# DCACHE_PORT_RANGE_PROTOCOLS_SERVER_MISC=60000,62000
#
# Sets the portrange for dcache as a GSIFTP client in "active" mode
#
# DCACHE_PORT_RANGE_PROTOCOLS_CLIENT_GSIFTP=33115,33215

# This option sets the pnfs server it defaults to the admin node if 
# not stated.
#
# DCACHE_PNFS_SERVER="pnfs_node"
#
# Sets the portrange for dcache as a GSIFTP server in "passive" mode
#
# DCACHE_PORT_RANGE_PROTOCOLS_SERVER_GSIFTP=50000,52000
#
# Sets the portrange for dcache as a (GSI)DCAP and xrootd server in 
# "passive" mode
#
# DCACHE_PORT_RANGE_PROTOCOLS_SERVER_MISC=60000,62000
#
# Sets the portrange for dcache as a GSIFTP client in "active" mode
#
# DCACHE_PORT_RANGE_PROTOCOLS_CLIENT_GSIFTP=33115,33215

# Only change if your site has an existing D-Cache installed
# To a different storage root.
# DCACHE_PNFS_VO_DIR="/pnfs/${MY_DOMAIN}/data"

# Set to "yes" only if YAIM shall reset the dCache configuration,
# or install DCache for the first time.
# i.e. if you want YAIM to configure dCache - WARNING:
# this may wipe out any dCache parameters previously configured!

# RESET_DCACHE_CONFIGURATION=no

# Set to "yes" only if YAIM shall reset the dCache nameserver,
# Or install DCache for the first time.
# i.e. if you want YAIM to clear the content of dCache - WARNING:
# this may wipe out any dCache files previously stored!
# RESET_DCACHE_PNFS=no

# Set to "yes" only if YAIM shall reset the dCache Databases,
# or install DCache for the first time.
# i.e. if you want YAIM to clear the metadata of dCache - WARNING:
# this may wipe out any dCache files names previously stored!
# Leaving your system without any way to reestablish which files 
# are stored.
# RESET_DCACHE_RDBMS=no



###############################
# DPM configuration variables #
###############################

# DPMDATA is now deprecated. Use an entry like $DPM_HOST:/filesystem in
# the DPM_FILESYSTEMS variable.
# From now on we use DPM_DB_USER and DPM_DB_PASSWORD to make clear
# its different role from that of the dpmmgr unix user who owns the
# directories and runs the daemons.

# The name of the DPM head node 
DPM_HOST="lxb7607v1.$MY_DOMAIN"   # my-dpm.$MY_DOMAIN

# The DPM pool name (max 15 character long name)
DPMPOOL=the_dpm_pool

# The filesystems/partitions parts of the pool
DPM_FILESYSTEMS="$DPM_HOST:/storage lxb7608v2.$MY_DOMAIN:/path2 lxfsrd0502.$MY_DOMAIN:/storage"

# The database user
DPM_DB_USER=dpmdbuser

# The database user password
DPM_DB_PASSWORD=dpmdbpwd-cert

# The DPM database host
DPM_DB_HOST=$DPM_HOST

# The DPM db name. Default is dpm_db
# DPM_DB=dpm_db

# The DPNS db name. Default is cns_db
# DPNS_DB=cns_db

# The DPM infosystem user name
DPM_INFO_USER=dpminfo

# The DPM infosystem user password
DPM_INFO_PASS=the-dpminfo-db-user-pwd

# Specifies the default amount of space reserved  for a file
DPMFSIZE=200M

# Variable for the port range  - Optional, default value is shown
# RFIO_PORT_RANGE="20000 25000" 

###########
# SE_LIST #
###########

SE_LIST="$CLASSIC_HOST $DPM_HOST"
# $DCACHE_ADMIN"
SE_ARCH="multidisk" # "disk, tape, multidisk, other"

#############################################
# GRIDFTP logfile location variable for SEs #
#############################################

# Variable necessary to configure Gridview service client on the SEs.
# It sets the location and filename of the gridftp server logfile on 
# different types of SEs. Needed gridftp logfile for gridview is the 
# netlogger file which contain info for each transfer (created with
# -Z/-log-transfer option for globus-gridftp-server). 
# Ex: DATE=20071206082249.108921 HOST=hostname.cern.ch PROG=globus-gridftp-server 
# NL.EVNT=FTP_INFO START=20071206082248.831173 USER=atlas102 FILE=/storage/atlas/ 
# BUFFER=0 BLOCK=262144 NBYTES=330 VOLUME=/ STREAMS=1 STRIPES=1 DEST=[127.0.0.1] 
# TYPE=LIST CODE=226
# Default locations for DPM: /var/log/dpm-gsiftp/dpm-gsiftp.log
#            and SE_classic: /var/log/globus-gridftp.log

SE_GRIDFTP_LOGFILE=/var/log/globus-gridftp.log



################################
# BDII configuration variables #
################################

WMS_HOST=lxbra2303.$MY_DOMAIN
VOMS_HOST=lxbra2309.$MY_DOMAIN

BDII_HOST=lxbra2305.$MY_DOMAIN
SITE_BDII_HOST=lxbra2306.$MY_DOMAIN

BDII_SITE_TIMEOUT=120
BDII_RESOURCE_TIMEOUT=`expr "$BDII_SITE_TIMEOUT" - 5`
GIP_RESPONSE=`expr "$BDII_RESOURCE_TIMEOUT" - 5`
GIP_FRESHNESS=60
GIP_CACHE_TTL=300
GIP_TIMEOUT=150

# Check the validity of this URL in the documentation
BDII_HTTP_URL="https://grid-deployment.web.cern.ch/grid-deployment/certification/lcgctbii-2305.conf"
#http://lcg-bdii-conf.cern.ch/bdii-conf/bdii.conf"

# The Freedom of Choice of Resources service allows a top-level BDII
# to be instructed to remove VO-specific access control lines for
# resources that do not meet the VO requirements
BDII_FCR=http://lcg-fcr.cern.ch:8083/fcr-data/exclude.ldif

# Ex.: BDII_REGIONS="CE SE RB PX VOBOX"
BDII_REGIONS="BDII CE CREAMCE SE DPM LFC PX FTS"
# MON"    # list of the services provided by the site

# The following examples are valid for node types using MDS. 
# If you the node type is using BDII instead (all 3.1 nodes)
# change the port to 2170 and mds-vo-name=resource
BDII_BDII_URL="ldap://$SITE_BDII_HOST:2170/mds-vo-name=resource,o=grid"
BDII_CE_URL="ldap://$CE_HOST:2170/mds-vo-name=resource,o=grid"
BDII_SE_URL="ldap://$CLASSIC_HOST:2170/mds-vo-name=resource,o=grid"
#BDII_RB_URL="ldap://$RB_HOST:2135/mds-vo-name=local,o=grid"
BDII_RB_URL="ldap://$WMS_HOST:2170/mds-vo-name=resource,o=grid"
BDII_PX_URL="ldap://$PX_HOST:2170/mds-vo-name=resource,o=grid"
BDII_LFC_URL="ldap://$LFC_HOST:2170/mds-vo-name=resource,o=grid"
#BDII_VOBOX_URL="ldap://$VOBOX_HOST:2135/mds-vo-name=local,o=grid"
BDII_FTS_URL="ldap://$FTS_HOST:2170/mds-vo-name=resource,o=grid"
BDII_DPM_URL="ldap://$DPM_HOST:2170/mds-vo-name=resource,o=grid"
BDII_CREAMCE_URL="ldap://$CREAMCE_HOST:2170/mds-vo-name=resource,o=grid"

##################################
# GLEXEC configuration variables #
##################################

GLEXEC_WN_OPMODE=setuid
GLEXEC_WN_SCAS_ENABLED=yes
SCAS_HOST=vtb-generic-115.cern.ch
SCAS_PORT=8443
GLEXEC_WN_LOG_DESTINATION=file
GLEXEC_WN_LOG_FILE=/var/log/glexec/glexec.log

##############################
# VO configuration variables #
##############################
#
# This file contains variables defined for the following VOs
# atlas
# alice
# lhcb
# cms
# dteam
# biomed
# ops
#
# Edit the following set of variables if you want to configure a different VO:
# VO_<vo_name>_SW_DIR
# VO_<vo_name>_DEFAULT_SE
# VO_<vo_name>_STORAGE_DIR 
# VO_<vo_name>_POOL_PATH  (optional)
# VO_<vo_name>_VOMSERVERS
# VO_<vo_name>_VOMS_EXTRA_MAPS (optional)
# VO_<vo_name>_VOMSES
# VO_<vo_name>_VOMS_CA_DN
# 
# If you are configuring a DNS-like VO, please check
# the following URL: https://twiki.cern.ch/twiki/bin/view/LCG/YaimGuide400#vo_d_directory
#
# IMPORTANT! Please, take into account that in the future YAIM will no longer provide VO
# related variables for these VOs. This information should be obtained out of the CIC portal:
# http://cic.in2p3.fr/
#
# The VO variables will be automatically generated by the YAIM configurator and integrated in YAIM. 

# Space separated list of supported VOs by your site
VOS="dteam org.glite.voms-test"
QUEUES=${VOS}

# For each queue define a _GROUP_ENABLE variable which is a list
# of VO names and VOMS FQANs
# Ex.: MYQUEUE_GROUP_ENABLE="ops atlas cms /VO=cms/GROUP=/cms/Susy"
# In DNS like VO names dots and dashes shoul be replaced with underscore:
# Ex.: MYQUEUE_GROUP_ENABLE="my.test-queue"
#      MY_TEST_QUEUE_GROUP_ENABLE="ops atlas"

DTEAM_GROUP_ENABLE="dteam"
ORG_GLITE_VOMS_TEST_GROUP_ENABLE="org.glite.voms-test
/VO=org.glite.voms-test/GROUP=/org.glite.voms-test/ROLE=lcgadmin
/VO=org.glite.voms-test/GROUP=/org.glite.voms-test/ROLE=production"

VO_SW_DIR=/opt/exp_soft

# Set this if you want a scratch directory for jobs
EDG_WL_SCRATCH=""
 
#########
# dteam #
#########
VO_DTEAM_SW_DIR=$VO_SW_DIR/dteam
VO_DTEAM_DEFAULT_SE=$CLASSIC_HOST
VO_DTEAM_STORAGE_DIR=$CLASSIC_STORAGE_DIR/dteam
VO_DTEAM_VOMS_SERVERS='vomss://lxbra2309.cern.ch:8443/voms/dteam?/dteam/'
VO_DTEAM_VOMSES="'dteam lcg-voms.cern.ch 15004 /DC=ch/DC=cern/OU=computers/CN=lcg-voms.cern.ch dteam 24' 'dteam voms.cern.ch 15004 /DC=ch/DC=cern/OU=computers/CN=voms.cern.ch dteam 24' 'dteam lxbra2309.cern.ch 15002 /DC=ch/DC=cern/OU=computers/CN=lxbra2309.cern.ch dteam 24'"
VO_DTEAM_VOMS_CA_DN="'/DC=ch/DC=cern/CN=CERN Trusted Certification Authority' '/DC=ch/DC=cern/CN=CERN Trusted Certification Authority' '/DC=ch/DC=cern/CN=CERN Trusted Certification Authority'"


#######################################
# vo.d contain org.glite.voms-test VO #
#######################################

VO_ORG_GLITE_VOMS_TEST_VOMSES="'org.glite.voms-test lxbra2309.cern.ch 15004 /DC=ch/DC=cern/OU=computers/CN=lxbra2309.cern.ch org.glite.voms-test'"
