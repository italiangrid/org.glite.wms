##############################################################################
#
# AUTHORS: Gianni Pucciani (CERN), Andrey Kiryanov (PNPI)
# CREATED: 8 December 2008
#
##############################################################################

The following scripts are meant to be used during the certification of the
first SCAS patch to run stress tests.


Files
-----

setup_test.exp

This Expect script is used to automatically login on several machines
and call a script to setup the test on each machine.
The usage is the following:
expect setup_test.exp <passwords file>  <node setup script> <log file location>

The passwords file is a text file with the list of machines with the 
associated root password separated by a colon ':'.
The first line is the user AFS login/pass.
E.g.
----------------------------------
afs_user:afs_pass
machine1:pass1
machine2:pass2
...
machinen:passn
----------------------------------

No comments can be included in this file.
The node setup script is a script that will be copied under /root of the
target machine and executed. This script is supposed to prepare the 
environment for the test on the target machine.
If the execution of the setup node is successful (i.e the node setup script 
returns '0'), an empty file with the name of the target machine will be 
created under the location specified by the last argument, the log file 
location.

It is important to remind that the node setup script must be available on
an AFS space where it can be retrieved.
The log file location must also be on an AFS space.


KNOWN ISSUES
From time to time to time the script signal an error in the log file
creation step, or it does not signal errors but the file does not
show up.
This problem appears randomly and it is usually solved calling the
script after a short pause of 10-30 seconds. 
In case an automatic ssh login can be done with the ssh-agent,
the next script must be used.

- setup_test.sh -
This script will be used in place of the previous expect script.
In order to run the script, you first have to launch the ssh-agent:
#eval `ssh-agent`
#ssh-add /home/<user>/.ssh/id_rsa
#ssh-add -l

Usage: ./setup_test.sh

The script is called without arguments, the machine names used to launch glexec requests
are hardcoded.
The script setup_test.cfg is sourced to export some variables used by this script.
The script creates a log file in the location specified in the configuration file, and
for each defined machine the script logs into it and:
- get an AFS token with a script stored in $get_afstoken_script (from the cfg file)
- touch a log file with the name of the machine in $log_location (from the cfg file)
- call the setup node script (explained later) stored in $setup_node_script (from the cfg file) 
passing as arguments the log file name just created plus an index used to discriminate the node.

- setup_test.cfg -
Configuration file for the previous script.
It exports the following variables:
setup_node_script
log_location
get_afstoken_script
pass_file
afs_pass_file
afs_user
users_certs_dir
glexec_stress_script
proxy_ren_script

- setup_node.sh -
Usage: ./setup_node.sh <index> <log file>
    <index> integer number to identify the node.
    <log file> the file that will be used to log data and start the test.

This script is called by the previous one.
It is used to setup a node on which the test will run and call the real test
script (glexec_stress_test.sh, hardcoded).
The operations that are done before calling the test script are:
 *get test_user_<index> cert/key and create a proxy
 *run a daemon to renew the proxy
 *retrieve the glexec test
 *launch the glexec test

- glexec_stress_test.sh -
Usage: ./glexec_stress_test.sh -f <log file> {-n <number>|-d <end date>} -i <index>
      <number> an integer number to state the number of tests to be done.
      <end date> a date until when to execute the test.
                 The format must be YYYYMMDDhhmm (returned by date +%Y%m%d%H%M).
                 E.g. 20 January 2009 at 8am => 200901200800
      <index> an integer number to identify the node

This script is called by the previous one.
It is the one used on the WN to launch a certain amount
of glexec commands.
In particular, the script will execute the glexec test either n times or until
a specified date. The starting of test is triggered when the word 'START' is 
found in the specified log file.
The log file will be also used to collect time information about the request.
The index passed with the -i option is used to distinguish node and test user.
The data file named <log file>_data will be created in the same directory as the
<log file> and will be used to store pairs (timestamp , response time of glexec call).
In the <log file> the output of the glexec call is stored.

- verify_glexec_output.sh -
Usage: ./verify_glexec_output.sh <mapped_user> <output file>
    <mapped_user> Unix user that should be returned by the glexec test
                  In case of pool accounts one can specify the prefix (without numbers).
    <output file> The file containing the output of the glexec test

This script is used to verify the output produced by the glexec_stress_test file,
which should contain just the word 'START' (inserted by the user to trigger the start
of the stress test) and the mapped user returned by the command:
$GLITE_LOCATION/sbin/glexec "/usr/bin/whoami".
Since the script look uses the regular expression [^$user], in case of pool accounts
one can just specify the prefix (E.g 'pildtm' can be specified to verify accounts
like 'pildtm01', 'pildtm10' etc..)

The file to be provided as second argument is the one created by the script
setup_test.sh, and it is named as the host that will write on that file.

- scas-mon.pl -
Usage: ./scas-mon.pl

This is a monitor script for SCAS daemon. Upon startup it will look through process
table for an active SCAS daemons.
A log file /var/tmp/scas-mon.log will be written in CSV format with the following
fields: Timestamp in seconds since epoch, Load1, Load5, Load15, Number of open FDs,
Memory consumption in kilobytes and number of SCAS processes.
Records are made every 5 seconds. Script does not accept any parameters and
all reconfiguration (process name, log file path, time interval) must be done
by editing the script (but default parameters are just fine).
Script will stay in memory even if all SCAS daemons die. It will pick ip new ones
as soon as they are started.

- combine.pl -
Usage: ./combine.pl <log1> <log2> ...

This script is used to combine log files from other scripts into one. Input files
should be specified as a command line arguments and output is written to stdout
(you probably want to redirect it somewhere). Input files should be in CSV format
with timestamp as a first field of every record. Script will add fields from specified
files in the order of appearance. All gaps will be filled automatically, values with
the same timestamp will be replaced by a mean value.
This script is useful for importing log information into applications like OpenOffice
or Gnuplot for further analysis.

- mkugconf.pl -
Usage: ./mkugconf.pl -v <vo>,... [-g <group>,...] [-r <role>,...] [-n <num>]
	<vo>	- VO name
	<group> - VOMS group
	<role>	- VOMS role
	<num>	- number of pool accounts per combination (10 by default)

This script is intended for easy creation of users.conf and groups.conf files for
YAIM. It accepts a comma-separated lists of VOs, groups and roles and creates both
files with all possible combinations.

- userwipe.pl -
Usage: ./userwipe.pl <uid regexp>

This script will erase all (pool) accounts with UIDs that match the regexp.
Corresponding home directories and groups will also be removed. You should
type "yes" on a terminal in order to let the script do its dirty job.

- proxy_renewal.sh -
Usage: ./proxy_renewal.sh <index>"
  <index> integer number to discriminate clients in the test"

This script creates a proxy certificate for test users 50x and
renew the proxy every hour.
The index that must be given as argument is used to choose the user.
The proxy is created into the current directory and copied
into the pilot user account: pilotdteamx


